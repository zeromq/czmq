zgossip(3)
==========

NAME
----
zgossip - gossip protocol service

SYNOPSIS
--------
----
//  This is zgossip, implemented as a CZMQ zactor task
void
    zgossip (zsock_t *pipe, void *args);

//  Self test of this class
void
    zgossip_test (bool verbose);
----

DESCRIPTION
-----------

Implements a gossip protocol (RFC TBD).

The gossip protocol distributes information around a loosely-connected
network of gossip services. The information consists of name/value pairs
published by applications at any point in the network. The goal of the
gossip protocol is to create eventual consistency between all the using
applications.

The name/value pairs (tuples) can be used for configuration data, for
status updates, for presence, or for discovery. When used for discovery,
the gossip protocol works as an alternative to e.g. UDP beaconing.

The gossip network consists of a set of loosely-coupled nodes that
exchange tuples. Nodes can be connected across arbitrary transports,
so the gossip network can have nodes that communicate over inproc,
over IPC, and/or over TCP, at the same time.

Each node runs the same stack, which is a server-client hybrid using
a modified Harmony pattern (from Chapter 8 of the Guide):
http://zguide.zeromq.org/page:all#True-Peer-Connectivity-Harmony-Pattern

Each node provides a ROUTER socket that accepts client connections on an
key defined by the application via a BIND command. The state machine
for these connections is in zgossip.xml, and the generated code is in
zgossip_engine.h.

Each node additionally creates outbound connections via DEALER sockets
to a set of servers ("remotes"), and under control of the calling app,
which sends CONNECT commands for each configured remote.

The messages between client and server are defined in zgossip_msg.xml.
This stack is built using the zeromq/zproto toolkit.

To join the gossip network, a node has to connect to one or more peers.
Every peer acts as a forwarder. This loosely-coupled network can scale
to thousands of nodes. However the gossip protocol is NOT designed to
be efficient, and should not be used for application data, as the same
tuples may be sent many times across the network.

The basic logic of the gossip service is to accept PUBLISH messages
from its owning application, and to forward these to every remote, and
every client it talks to. When a node gets a duplicate tuple, it throws
it away. When a node gets a new tuple, it stores it, and fowards it as
just described. At any point the application can access the node's set
of tuples.

The protocol uses ping-pong heartbeating to monitor presence. This code
doesn't do anything with expired nodes yet.

The assumptions in this design are:

* The data set is slow-changing. Thus, the cost of the gossip protocol
  is irrelevant with respect to other traffic.

EXAMPLE
-------
.From zgossip_test method
----
    //  Test basic client-to-server operation of the protocol
    zactor_t *server = zactor_new (zgossip, "server");
    zstr_sendx (server, "SET", "server/animate", verbose? "1": "0", NULL);
    zstr_sendx (server, "BIND", "ipc:///tmp/zgossip", NULL);
    char *port_str = zstr_recv (server);
    assert (streq (port_str, "0"));
    zstr_free (&port_str);

    zsock_t *client = zsock_new (ZMQ_DEALER);
    assert (client);
    zsock_set_rcvtimeo (client, 2000);
    zsock_connect (client, "ipc:///tmp/zgossip");

    //  Send HELLO, which gets no reply
    zgossip_msg_t *request, *reply;
    request = zgossip_msg_new (ZGOSSIP_MSG_HELLO);
    zgossip_msg_send (&request, client);

    //  Send PING, expect PONG back
    request = zgossip_msg_new (ZGOSSIP_MSG_PING);
    zgossip_msg_send (&request, client);
    reply = zgossip_msg_recv (client);
    assert (reply);
    assert (zgossip_msg_id (reply) == ZGOSSIP_MSG_PONG);
    zgossip_msg_destroy (&reply);
    
    zactor_destroy (&server);

    zsock_destroy (&client);
    zactor_destroy (&server);

    //  Test peer-to-peer operations
    zactor_t *base = zactor_new (zgossip, "base");
    assert (base);
    zstr_sendx (base, "SET", "server/animate", verbose? "1": "0", NULL);
    //  Set a 100msec timeout on clients so we can test expiry
    zstr_sendx (base, "SET", "server/timeout", "100", NULL);
    zstr_sendx (base, "BIND", "inproc://base", NULL);
    port_str = zstr_recv (base);
    assert (streq (port_str, "0"));
    zstr_free (&port_str);

    zactor_t *alpha = zactor_new (zgossip, "alpha");
    assert (alpha);
    zstr_sendx (alpha, "CONNECT", "inproc://base", NULL);
    zstr_sendx (alpha, "PUBLISH", "inproc://alpha-1", "service1", NULL);
    zstr_sendx (alpha, "PUBLISH", "inproc://alpha-2", "service2", NULL);

    zactor_t *beta = zactor_new (zgossip, "beta");
    assert (beta);
    zstr_sendx (beta, "CONNECT", "inproc://base", NULL);
    zstr_sendx (beta, "PUBLISH", "inproc://beta-1", "service1", NULL);
    zstr_sendx (beta, "PUBLISH", "inproc://beta-2", "service2", NULL);

    //  got nothing
    zclock_sleep (200);
    
    zactor_destroy (&base);
    zactor_destroy (&alpha);
    zactor_destroy (&beta);
    
----

SEE ALSO
--------
linkczmq:czmq[7]
